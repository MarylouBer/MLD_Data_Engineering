# Project 1: Web Scraping and Data Pipeline

This is a real-world application, automating the flow of data from external sources to a structured format for analysis—great practice for building scalable data pipelines!

### What I’ve been up to:
- **Web Scraping**: Extracted data from Wikipedia using Python libraries like `BeautifulSoup` and `requests`.
- **Data Transformation**: Cleaned and transformed the data with `pandas`, including currency conversions using a public API.
- **Database Integration**: Loaded the processed data into an SQLite database, preparing it for structured querying.
- **Testing**: Ran SQL queries to validate the structure and usability of the stored data.

